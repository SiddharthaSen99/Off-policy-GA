{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "from torch.distributions import Categorical\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "#Hyper-parameters\n",
    "max_episodes = 1000          # max training episodes\n",
    "max_timesteps = 250          # max timesteps in one episode\n",
    "gamma = 0.01                # discount factor\n",
    "gamma1 = 0.99\n",
    "epsilon = 0.2                #need to change it to max(advantage)\n",
    "dkl=1                       #need to change it to KL divergence between old and new policies\n",
    "Q_r=[]\n",
    "Q_r1=[]\n",
    "a=[]\n",
    "Q=np.zeros((max_timesteps,2))\n",
    "mutation_power = 0.02#hyper-parameter, set from https://arxiv.org/pdf/1712.06567.pdf\n",
    "#print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartPoleAI(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.fc = nn.Sequential(\n",
    "                        nn.Linear(4,128, bias=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(128,2, bias=True),\n",
    "                        nn.Softmax(dim=1)\n",
    "                        )\n",
    "\n",
    "                \n",
    "        def forward(self, inputs):\n",
    "            x = self.fc(inputs)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    \n",
    "        # nn.Conv2d weights are of shape [16, 1, 3, 3] i.e. # number of filters, 1, stride, stride\n",
    "        # nn.Conv2d bias is of shape [16] i.e. # number of filters\n",
    "        \n",
    "        # nn.Linear weights are of shape [32, 24336] i.e. # number of input features, number of output features\n",
    "        # nn.Linear bias is of shape [32] i.e. # number of output features\n",
    "        \n",
    "        if ((type(m) == nn.Linear) | (type(m) == nn.Conv2d)):\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "            m.bias.data.fill_(0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def behavioural_policy(agents):\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_divergence(agent1,agent2):\n",
    "    return KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_random_agents(num_agents):\n",
    "    \n",
    "    agents = []\n",
    "    for _ in range(num_agents):\n",
    "        \n",
    "        agent = CartPoleAI()\n",
    "        \n",
    "        for param in agent.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        init_weights(agent)\n",
    "        agents.append(agent)\n",
    "        \n",
    "        \n",
    "    return agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agents(agents):\n",
    "    \n",
    "    reward_agents = []\n",
    "    env = gym.make(\"CartPole-v0\")\n",
    "    #print(\"Enter\")\n",
    "    for agent in agents:#There is only one agent in the list. But it is necessary to pass the agents in the form of lists to make it iterable and work on it\n",
    "        agent.eval()\n",
    "        #print(\"HELLLO!!!!!!\")\n",
    "        observation = env.reset()\n",
    "        r=0\n",
    "        a.clear()\n",
    "        Q_r1.clear()\n",
    "        Q_r.clear()\n",
    "        for i in range(max_timesteps):\n",
    "            \n",
    "            inp = torch.tensor(observation).type('torch.FloatTensor').view(1,-1)\n",
    "            output_probabilities = agent(inp).detach().numpy()[0]\n",
    "            #print(output_probabilities)\n",
    "            Q[i][0]=output_probabilities[0]\n",
    "            Q[i][1]=output_probabilities[1]\n",
    "            action = np.random.choice(range(game_actions), 1, p=output_probabilities).item()\n",
    "            a.append(action)\n",
    "            new_observation, reward, done, info = env.step(action)\n",
    "            #r+=(gamma1**i)*reward\n",
    "            r+=reward\n",
    "            Q_r.append(reward)\n",
    "            observation = new_observation\n",
    "            if(done):\n",
    "                break\n",
    "\n",
    "        #reward_agents.append(r)\n",
    "        #reward_agents.append(s)\n",
    "        #print(\"Non-discounted Reward:::\",Q_r)\n",
    "        #for rew in reversed(Q_r):\n",
    "        #    if rew==Q_r[len(Q_r)-1]:\n",
    "        #        d_r=0\n",
    "        #    else:\n",
    "        #        d_r=rew+gamma1*d_r\n",
    "        #    Q_r1.insert(0,d_r)\n",
    "        for i in range(len(Q_r)):\n",
    "            d_r=0\n",
    "            c=0\n",
    "            for j in range(i+1,len(Q_r)):\n",
    "                d_r+=(gamma1**c)*Q_r[j]\n",
    "                c+=1\n",
    "            Q_r1.append(d_r)\n",
    "            \n",
    "        reward_agents.append(r)\n",
    "    #print(\"Exit\")\n",
    "    #Q=Q[~np.all(Q==0,axis=1)]\n",
    "    #print(\"Reward:::\",reward_agents)\n",
    "    #print(\"Probabilities:::\",Q)\n",
    "    #print(\"Actions:::\",a)\n",
    "    #for i in range()\n",
    "    #print(\"Discounted Reward,i.e,Q:::\",Q_r1)\n",
    "    \n",
    "    \n",
    "    return reward_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_target_agents(agents):\n",
    "    \n",
    "    reward_agents = []\n",
    "    env = gym.make(\"CartPole-v0\")\n",
    "    #print(\"Enter\")\n",
    "    for agent in agents:#There is only one agent in the list. But it is necessary to pass the agents in the form of lists to make it iterable and work on it\n",
    "        agent.eval()\n",
    "        #print(\"HELLLO!!!!!!\")\n",
    "        observation = env.reset()\n",
    "        r=0\n",
    "        s=0\n",
    "        i=0\n",
    "        #print(\"SIZE OF ACTIONS:\",len(a),\"SIZE OF PROBABILITIES:\",Q.shape,\"SIZE OF DISCOUNTED REWARDS:\",len(Q_r1))\n",
    "        for i in range(len(Q_r1)):\n",
    "            \n",
    "            inp = torch.tensor(observation).type('torch.FloatTensor').view(1,-1)\n",
    "            output_probabilities = agent(inp).detach().numpy()[0]\n",
    "            L_pi=(output_probabilities[a[i]]/Q[i][a[i]])*Q_r1[i]\n",
    "            #print(\"Ratios :\",output_probabilities[a[i]]/Q[i][a[i]])\n",
    "            #print(\"Q value:\",Q_r1[i])\n",
    "            #print(\"L_pi\",L_pi)\n",
    "            #surr1= L_pi-(4*max(Q_r1)*gamma*dkl/np.square(1-gamma))\n",
    "            \n",
    "            #print(output_probabilities)\n",
    "            s+=L_pi\n",
    "            action = np.random.choice(range(game_actions), 1, p=output_probabilities).item()\n",
    "            new_observation, reward, done, info = env.step(action)\n",
    "            #r+=(gamma**i)*reward\n",
    "            \n",
    "            #s=s+1\n",
    "            observation = new_observation\n",
    "\n",
    "            if(done):\n",
    "                break\n",
    "        #print(\"S:\",s)\n",
    "        #print(\"Max Q_r1:\",max(Q_r1))\n",
    "        #surr1= s-(4*max(Q_r1)*gamma*dkl/np.square(1-gamma))\n",
    "        #print(\"Surr1:\",surr1)\n",
    "        #reward_agents.append(surr1)        \n",
    "        reward_agents.append(s)\n",
    "    #print(\"Exit\")\n",
    "    #print(\"REWARD AGENTS\",reward_agents)\n",
    "    #print(reward_agents)\n",
    "    return reward_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alternate_average_score(agent, runs):\n",
    "    score = 0.\n",
    "    for i in range(runs):\n",
    "        score += run_target_agents([agent])[0]\n",
    "    return score/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_average_score(agent, runs):\n",
    "    score = 0.\n",
    "    for i in range(runs):\n",
    "        score += run_agents([agent])[0]\n",
    "    return score/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agents_n_times(agents, runs):\n",
    "    avg_score = []\n",
    "    index = 0\n",
    "    for agent in agents:\n",
    "        if index==0:\n",
    "            avg_score.append(return_average_score(agent,runs))\n",
    "        else:\n",
    "            avg_score.append(alternate_average_score(agent,runs))\n",
    "        index+=1\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agents_n_times_again(agents, runs):\n",
    "    avg_score = []\n",
    "    for agent in agents:\n",
    "        avg_score.append(return_average_score(agent,runs))\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(agent):\n",
    "\n",
    "    child_agent = copy.deepcopy(agent)\n",
    "            \n",
    "    for param in child_agent.parameters():\n",
    "    \n",
    "        if(len(param.shape)==4): #weights of Conv2D\n",
    "\n",
    "            for i0 in range(param.shape[0]):\n",
    "                for i1 in range(param.shape[1]):\n",
    "                    for i2 in range(param.shape[2]):\n",
    "                        for i3 in range(param.shape[3]):\n",
    "                            \n",
    "                            param[i0][i1][i2][i3]+= mutation_power * np.random.rand()\n",
    "                                \n",
    "                                    \n",
    "\n",
    "        elif(len(param.shape)==2): #weights of linear layer\n",
    "            for i0 in range(param.shape[0]):\n",
    "                for i1 in range(param.shape[1]):\n",
    "                    \n",
    "                    param[i0][i1]+= mutation_power * np.random.randn()\n",
    "                        \n",
    "\n",
    "        elif(len(param.shape)==1): #biases of linear layer or conv layer\n",
    "            for i0 in range(param.shape[0]):\n",
    "                \n",
    "                param[i0]+=mutation_power * np.random.randn()\n",
    "\n",
    "    return child_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_children(agents, sorted_parent_indexes, elite_index):\n",
    "    \n",
    "    children_agents = []\n",
    "    \n",
    "    #first take selected parents from sorted_parent_indexes and generate N-1 children\n",
    "    for i in range(len(agents)-1):\n",
    "        \n",
    "        selected_agent_index = sorted_parent_indexes[np.random.randint(len(sorted_parent_indexes))]\n",
    "        children_agents.append(mutate(agents[selected_agent_index]))\n",
    "\n",
    "    #now add one elite\n",
    "    elite_child = add_elite(agents, sorted_parent_indexes, elite_index)\n",
    "    children_agents.append(elite_child)\n",
    "    elite_index=len(children_agents)-1 #it is the last one\n",
    "    \n",
    "    return children_agents, elite_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elite(agents, sorted_parent_indexes, elite_index=None, only_consider_top_n=10):\n",
    "    \n",
    "    candidate_elite_index = sorted_parent_indexes[:only_consider_top_n]\n",
    "    \n",
    "    if(elite_index is not None):\n",
    "        candidate_elite_index = np.append(candidate_elite_index,[elite_index])\n",
    "        \n",
    "    top_score = None\n",
    "    top_elite_index = None\n",
    "    \n",
    "    for i in candidate_elite_index:\n",
    "        score = return_average_score(agents[i],runs=5)\n",
    "        print(\"Score for elite i \", i, \" is \", score)\n",
    "        \n",
    "        if(top_score is None):\n",
    "            top_score = score\n",
    "            top_elite_index = i\n",
    "        elif(score > top_score):\n",
    "            top_score = score\n",
    "            top_elite_index = i\n",
    "            \n",
    "    print(\"Elite selected with index \",top_elite_index, \" and score\", top_score)\n",
    "    \n",
    "    child_agent = copy.deepcopy(agents[top_elite_index])\n",
    "    return child_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta_pi : [21.09, 24.06, 23.33, 18.99, 22.66, 29.02, 20.38, 21.45, 22.55, 18.44]\n",
      "Corresponding L_pi values : [21.63, 201.66225869600046, 208.7758570351208, 199.32543493233425, 199.2597431974435, 208.52772138772423, 197.0574939496903, 201.1018330478771, 201.76358497380352, 202.23090034476144]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "game_actions = 2 #2 actions possible: left or right\n",
    "\n",
    "#disable gradients as we will not use them\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# initialize N number of agents\n",
    "num_agents = 10\n",
    "agents = return_random_agents(num_agents)\n",
    "\n",
    "elite_index = None\n",
    "\n",
    "rewards2 = run_agents_n_times_again(agents,100)\n",
    "rewards = run_agents_n_times(agents, 100) #return average of multiple runs\n",
    "\n",
    "\n",
    "print(\"Eta_pi :\",rewards2)\n",
    "print(\"Corresponding L_pi values :\",rewards)\n",
    "\n",
    "xpoints = [1,2,3,4,5,6,7,8,9,10]\n",
    "plt.plot(xpoints,rewards)\n",
    "plt.plot(xpoints,rewards2)\n",
    "plt.title('Eta_pi vs L_pi:Comparison')\n",
    "plt.xlabel('Policies')\n",
    "plt.ylabel('Eta_pi(Orange) vs L_pi(Blue)')\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
