{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "FinalNeuroEvolution.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm8PnKUy1A6_"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from statistics import mean"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFL8mtv31A7D"
      },
      "source": [
        "from gym.wrappers import Monitor"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTqufjzT1A7E"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wibDDlD31A7F"
      },
      "source": [
        "import math\n",
        "import copy\n",
        "from torch.distributions import Categorical\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnRqQR4J1A7G"
      },
      "source": [
        "#Hyper-parameters\n",
        "max_episodes = 1000          # max training episodes\n",
        "max_timesteps = 250          # max timesteps in one episode\n",
        "gamma = 0.01                # discount factor\n",
        "gamma1 = 0.99\n",
        "epsilon = 0.2                #need to change it to max(advantage)\n",
        "dkl=1                       #need to change it to KL divergence between old and new policies\n",
        "Q_r=[]\n",
        "Q_r1=[]\n",
        "a=[]\n",
        "Q=np.zeros((max_timesteps,2))\n",
        "mutation_power = 0.02#hyper-parameter, set from https://arxiv.org/pdf/1712.06567.pdf\n",
        "#print(Q)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0BvA61z1A7H"
      },
      "source": [
        "class CartPoleAI(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.fc = nn.Sequential(\n",
        "                        nn.Linear(4,128, bias=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(128,2, bias=True),\n",
        "                        nn.Softmax(dim=1)\n",
        "                        )\n",
        "\n",
        "                \n",
        "        def forward(self, inputs):\n",
        "            x = self.fc(inputs)\n",
        "            return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwHYvxqD1A7I"
      },
      "source": [
        "def init_weights(m):\n",
        "    \n",
        "        # nn.Conv2d weights are of shape [16, 1, 3, 3] i.e. # number of filters, 1, stride, stride\n",
        "        # nn.Conv2d bias is of shape [16] i.e. # number of filters\n",
        "        \n",
        "        # nn.Linear weights are of shape [32, 24336] i.e. # number of input features, number of output features\n",
        "        # nn.Linear bias is of shape [32] i.e. # number of output features\n",
        "        \n",
        "        if ((type(m) == nn.Linear) | (type(m) == nn.Conv2d)):\n",
        "            torch.nn.init.xavier_uniform(m.weight)\n",
        "            m.bias.data.fill_(0.00)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1NIXT0m1A7J"
      },
      "source": [
        "def behavioural_policy(agents):\n",
        "    return agent"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AyQNnsv1A7J"
      },
      "source": [
        "def KL_divergence(agent1,agent2):\n",
        "    return KL"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc_t1RDB1A7K"
      },
      "source": [
        "def return_random_agents(num_agents):\n",
        "    \n",
        "    agents = []\n",
        "    for _ in range(num_agents):\n",
        "        \n",
        "        agent = CartPoleAI()\n",
        "        \n",
        "        for param in agent.parameters():\n",
        "            param.requires_grad = False\n",
        "            \n",
        "        init_weights(agent)\n",
        "        agents.append(agent)\n",
        "        \n",
        "        \n",
        "    return agents"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCER7U_R1A7L"
      },
      "source": [
        "def run_agents(agents):\n",
        "    \n",
        "    reward_agents = []\n",
        "    env = gym.make(\"CartPole-v0\")\n",
        "    #print(\"Enter\")\n",
        "    for agent in agents:#There is only one agent in the list. But it is necessary to pass the agents in the form of lists to make it iterable and work on it\n",
        "        agent.eval()\n",
        "        #print(\"HELLLO!!!!!!\")\n",
        "        observation = env.reset()\n",
        "        r=0\n",
        "        a.clear()\n",
        "        Q_r1.clear()\n",
        "        Q_r.clear()\n",
        "        for i in range(max_timesteps):\n",
        "            \n",
        "            inp = torch.tensor(observation).type('torch.FloatTensor').view(1,-1)\n",
        "            output_probabilities = agent(inp).detach().numpy()[0]\n",
        "            #print(output_probabilities)\n",
        "            Q[i][0]=output_probabilities[0]\n",
        "            Q[i][1]=output_probabilities[1]\n",
        "            action = np.random.choice(range(game_actions), 1, p=output_probabilities).item()\n",
        "            a.append(action)\n",
        "            new_observation, reward, done, info = env.step(action)\n",
        "            #r+=(gamma1**i)*reward\n",
        "            Q_r.append(reward)\n",
        "            observation = new_observation\n",
        "            if(done):\n",
        "                break\n",
        "\n",
        "        #reward_agents.append(r)\n",
        "        #reward_agents.append(s)\n",
        "        #print(\"Non-discounted Reward:::\",Q_r)\n",
        "        #for rew in reversed(Q_r):\n",
        "        #    if rew==Q_r[len(Q_r)-1]:\n",
        "        #        d_r=0\n",
        "        #    else:\n",
        "        #        d_r=rew+gamma1*d_r\n",
        "        #    Q_r1.insert(0,d_r)\n",
        "        for i in range(len(Q_r)):\n",
        "            d_r=0\n",
        "            c=0\n",
        "            for j in range(i+1,len(Q_r)):\n",
        "                d_r+=(gamma1**c)*Q_r[j]\n",
        "                c+=1\n",
        "            Q_r1.append(d_r)\n",
        "            \n",
        "        reward_agents.append(sum(Q_r1))\n",
        "    #print(\"Exit\")\n",
        "    #Q=Q[~np.all(Q==0,axis=1)]\n",
        "    #print(\"Reward:::\",reward_agents)\n",
        "    #print(\"Probabilities:::\",Q)\n",
        "    #print(\"Actions:::\",a)\n",
        "    #for i in range()\n",
        "    #print(\"Discounted Reward,i.e,Q:::\",Q_r1)\n",
        "    \n",
        "    \n",
        "    return reward_agents"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_NAWS2N1A7M"
      },
      "source": [
        "def run_target_agents(agents):\n",
        "    \n",
        "    reward_agents = []\n",
        "    env = gym.make(\"CartPole-v0\")\n",
        "    #print(\"Enter\")\n",
        "    for agent in agents:#There is only one agent in the list. But it is necessary to pass the agents in the form of lists to make it iterable and work on it\n",
        "        agent.eval()\n",
        "        #print(\"HELLLO!!!!!!\")\n",
        "        observation = env.reset()\n",
        "        r=0\n",
        "        s=0\n",
        "        i=0\n",
        "        #print(\"SIZE OF ACTIONS:\",len(a),\"SIZE OF PROBABILITIES:\",Q.shape,\"SIZE OF DISCOUNTED REWARDS:\",len(Q_r1))\n",
        "        for i in range(len(Q_r1)):\n",
        "            \n",
        "            inp = torch.tensor(observation).type('torch.FloatTensor').view(1,-1)\n",
        "            output_probabilities = agent(inp).detach().numpy()[0]\n",
        "            L_pi=(output_probabilities[a[i]]/Q[i][a[i]])*Q_r1[i]\n",
        "            #print(\"Ratios :\",output_probabilities[a[i]]/Q[i][a[i]])\n",
        "            #print(\"Q value:\",Q_r1[i])\n",
        "            #print(\"L_pi\",L_pi)\n",
        "            #surr1= L_pi-(4*max(Q_r1)*gamma*dkl/np.square(1-gamma))\n",
        "            \n",
        "            #print(output_probabilities)\n",
        "            s+=L_pi\n",
        "            action = np.random.choice(range(game_actions), 1, p=output_probabilities).item()\n",
        "            new_observation, reward, done, info = env.step(action)\n",
        "            #r+=(gamma**i)*reward\n",
        "            \n",
        "            #s=s+1\n",
        "            observation = new_observation\n",
        "\n",
        "            if(done):\n",
        "                break\n",
        "        #print(\"S:\",s)\n",
        "        #print(\"Max Q_r1:\",max(Q_r1))\n",
        "        #surr1= s-(4*max(Q_r1)*gamma*dkl/np.square(1-gamma))\n",
        "        #print(\"Surr1:\",surr1)\n",
        "        #reward_agents.append(surr1)        \n",
        "        reward_agents.append(s)\n",
        "    #print(\"Exit\")\n",
        "    #print(\"REWARD AGENTS\",reward_agents)\n",
        "    #print(reward_agents)\n",
        "    return reward_agents"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvqvN-yS1A7O"
      },
      "source": [
        "def alternate_average_score(agent, runs):\n",
        "    score = 0.\n",
        "    for i in range(runs):\n",
        "        score += run_target_agents([agent])[0]\n",
        "    return score/runs"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh0sF0ZQ1A7P"
      },
      "source": [
        "def return_average_score(agent, runs):\n",
        "    score = 0.\n",
        "    for i in range(runs):\n",
        "        score += run_agents([agent])[0]\n",
        "    return score/runs\n",
        "    "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9q0Qvci9TSi"
      },
      "source": [
        "def get_output_probabilities(agent):\n",
        "\n",
        "  # We sample the agent for several nummber of iterations\n",
        "\n",
        "  number_of_iterations = 1000\n",
        "  val = [0 , 0]\n",
        "\n",
        "  for itr in range(number_of_iterations):\n",
        "    input = torch.randn(128,4)\n",
        "    probability = agent(input).detach().numpy()[0]\n",
        "    # print(\"itr = \",itr,\" value = \",probability)\n",
        "    for i in range(len(probability)):\n",
        "      val[i] += probability[i]\n",
        "\n",
        "  for i in range(len(probability)):\n",
        "    val[i] /= number_of_iterations\n",
        "  \n",
        "  # This sampling provides us with a representation of our agent function\n",
        "  # in terms of probabilties which we pass through\n",
        "\n",
        "  # print(val)\n",
        "  return val"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnsW3moM9lYG"
      },
      "source": [
        "def create_cluster(unassigned, probability_representation,cluster_size):\n",
        "  created_cluster = []\n",
        "  KLVals = []\n",
        "\n",
        "  min_KL_Val = 1e9\n",
        "  cluster_size = min(cluster_size,len(unassigned))\n",
        "\n",
        "  # print(\"Cluster size for this iteration = \",cluster_size,\" #still unassigned = \",len(unassigned))\n",
        "  \n",
        "  for itr in range(len(probability_representation)):\n",
        "    sum = 0\n",
        "\n",
        "    if itr not in unassigned: continue\n",
        "\n",
        "    KLVals.clear()\n",
        "    for i in range(len(probability_representation)):\n",
        "      if i not in unassigned: continue\n",
        "      KLval = 0\n",
        "      prob1 = probability_representation[itr]\n",
        "      prob2 = probability_representation[i]\n",
        "      for variable in range(len(prob1)):\n",
        "        KLval += prob1[variable]*np.log(prob1[variable]/prob2[variable])\n",
        "      KLVals.append([KLval,i])\n",
        "\n",
        "    KLVals.sort()\n",
        "        \n",
        "    for j in range(cluster_size):\n",
        "      sum += KLVals[j][0]\n",
        "    # print(\"KLVals for \",itr,\" = \", sum)\n",
        "    if min_KL_Val > sum:\n",
        "      min_KL_Val = sum\n",
        "      created_cluster.clear()\n",
        "      for j in range(cluster_size):\n",
        "        created_cluster.append(KLVals[j][1])\n",
        "\n",
        "  print(\"created cluster is \",created_cluster)\n",
        "  for agent in created_cluster:\n",
        "    unassigned.remove(agent)\n",
        "\n",
        "  \n",
        "  return created_cluster, unassigned"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXhLq8ix9oOT"
      },
      "source": [
        "\n",
        "def clustering(agents,num_agents):\n",
        "\n",
        "  # Our cluser size is arbitrary, treated as an hyper parameter\n",
        "\n",
        "  number_of_clusters = int(math.sqrt(num_agents))\n",
        "  cluster_size = int(num_agents/number_of_clusters)\n",
        "\n",
        "  print(\"forming clusers of size = \",cluster_size)\n",
        "\n",
        "  probability_representation = []\n",
        "\n",
        "  for agent in agents:\n",
        "    required = get_output_probabilities(agent)\n",
        "    probability_representation.append(required)\n",
        "\n",
        "  unassigned = [x for x in range(num_agents)] \n",
        "  # Checks for policies that are not clusered yet\n",
        "\n",
        "  root = [0 for i in range(num_agents)]\n",
        "  # root[i] is the behaviour policy for taget policy i\n",
        "\n",
        "  while len(unassigned) > 0:\n",
        "    created_cluster, unassigned = create_cluster(unassigned, probability_representation,cluster_size)\n",
        "    for itr in created_cluster:\n",
        "      root[itr] = created_cluster[0] \n",
        "      # 0th index is behavior policy for cluster i\n",
        "\n",
        "  return root"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTOafJUG1A7P"
      },
      "source": [
        "def run_agents_n_times(agents, runs):\n",
        "    avg_score = []\n",
        "    index = 0\n",
        "\n",
        "    clustered = clustering(agents,num_agents)\n",
        "\n",
        "    ordering = []\n",
        "\n",
        "    itr = 0\n",
        "    for agent in clustered:\n",
        "      ordering.append([agent,itr])\n",
        "      itr += 1\n",
        "    # ordering.sort()\n",
        "\n",
        "    for i in range(1,len(ordering)):\n",
        "      return_average_score(agents[ordering[i][0]],runs)\n",
        "      avg_score.append(alternate_average_score(agents[ordering[i][1]],runs))\n",
        "      index+=1\n",
        "    return avg_score"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32SiZzLo1A7Q"
      },
      "source": [
        "def mutate(agent):\n",
        "\n",
        "    child_agent = copy.deepcopy(agent)\n",
        "            \n",
        "    for param in child_agent.parameters():\n",
        "    \n",
        "        if(len(param.shape)==4): #weights of Conv2D\n",
        "\n",
        "            for i0 in range(param.shape[0]):\n",
        "                for i1 in range(param.shape[1]):\n",
        "                    for i2 in range(param.shape[2]):\n",
        "                        for i3 in range(param.shape[3]):\n",
        "                            \n",
        "                            param[i0][i1][i2][i3]+= mutation_power * np.random.rand()\n",
        "                                \n",
        "                                    \n",
        "\n",
        "        elif(len(param.shape)==2): #weights of linear layer\n",
        "            for i0 in range(param.shape[0]):\n",
        "                for i1 in range(param.shape[1]):\n",
        "                    \n",
        "                    param[i0][i1]+= mutation_power * np.random.randn()\n",
        "                        \n",
        "\n",
        "        elif(len(param.shape)==1): #biases of linear layer or conv layer\n",
        "            for i0 in range(param.shape[0]):\n",
        "                \n",
        "                param[i0]+=mutation_power * np.random.randn()\n",
        "\n",
        "    return child_agent"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CUfSBPM1A7Q"
      },
      "source": [
        "def return_children(agents, sorted_parent_indexes, elite_index):\n",
        "    \n",
        "    children_agents = []\n",
        "    \n",
        "    #first take selected parents from sorted_parent_indexes and generate N-1 children\n",
        "    for i in range(len(agents)-1):\n",
        "        \n",
        "        selected_agent_index = sorted_parent_indexes[np.random.randint(len(sorted_parent_indexes))]\n",
        "        children_agents.append(mutate(agents[selected_agent_index]))\n",
        "\n",
        "    #now add one elite\n",
        "    elite_child = add_elite(agents, sorted_parent_indexes, elite_index)\n",
        "    children_agents.append(elite_child)\n",
        "    elite_index=len(children_agents)-1 #it is the last one\n",
        "    \n",
        "    return children_agents, elite_index"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCbdrFwC1A7R"
      },
      "source": [
        "def add_elite(agents, sorted_parent_indexes, elite_index=None, only_consider_top_n=10):\n",
        "    \n",
        "    candidate_elite_index = sorted_parent_indexes[:only_consider_top_n]\n",
        "    \n",
        "    if(elite_index is not None):\n",
        "        candidate_elite_index = np.append(candidate_elite_index,[elite_index])\n",
        "        \n",
        "    top_score = None\n",
        "    top_elite_index = None\n",
        "    \n",
        "    for i in candidate_elite_index:\n",
        "        score = return_average_score(agents[i],runs=5)\n",
        "        print(\"Score for elite i \", i, \" is \", score)\n",
        "        \n",
        "        if(top_score is None):\n",
        "            top_score = score\n",
        "            top_elite_index = i\n",
        "        elif(score > top_score):\n",
        "            top_score = score\n",
        "            top_elite_index = i\n",
        "            \n",
        "    print(\"Elite selected with index \",top_elite_index, \" and score\", top_score)\n",
        "    \n",
        "    child_agent = copy.deepcopy(agents[top_elite_index])\n",
        "    return child_agent"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldxPIma31A7S"
      },
      "source": [
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gv4o-pnT1A7T",
        "outputId": "de877997-baf8-4b26-eeab-9f6e39eda88d"
      },
      "source": [
        "game_actions = 2 #2 actions possible: left or right\n",
        "\n",
        "#disable gradients as we will not use them\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "# initialize N number of agents\n",
        "num_agents = 100\n",
        "agents = return_random_agents(num_agents)\n",
        "\n",
        "# How many top agents to consider as parents\n",
        "top_limit = 10\n",
        "\n",
        "# run evolution until X generations\n",
        "generations = 10\n",
        "\n",
        "elite_index = None\n",
        "n=[]\n",
        "m=[]\n",
        "\n",
        "for generation in range(generations):\n",
        "\n",
        "    # return rewards of agents\n",
        "    rewards = run_agents_n_times(agents, 100) #return average of multiple runs\n",
        "    #print(rewards)\n",
        "    #sort by rewards\n",
        "    sorted_parent_indexes = np.argsort(rewards)[::-1][:top_limit] #reverses and gives top values (argsort sorts by ascending by default) https://stackoverflow.com/questions/16486252/is-it-possible-to-use-argsort-in-descending-order\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    top_rewards = []\n",
        "    \n",
        "    for best_parent in sorted_parent_indexes:\n",
        "        top_rewards.append(rewards[best_parent])\n",
        "    \n",
        "    print(\"Generation \", generation, \" | Mean rewards: \", np.mean(rewards), \" | Mean of top 5: \",np.mean(top_rewards[:5]))\n",
        "    #print(rewards)\n",
        "    print(\"The minimum reward is earned is \",min(rewards),\"by the \",rewards.index(min(rewards))+1,\"th agent\")\n",
        "    print(\"Top \",top_limit,\" scores\", sorted_parent_indexes)\n",
        "    print(\"Rewards for top: \",top_rewards)\n",
        "    \n",
        "    m.append(np.mean(top_rewards))\n",
        "    n.append(np.mean(rewards))\n",
        "    # setup an empty list for containing children agents\n",
        "    children_agents, elite_index = return_children(agents, sorted_parent_indexes, elite_index)\n",
        "\n",
        "    # kill all agents, and replace them with their children\n",
        "    agents = children_agents\n",
        "x=np.arange(generations)\n",
        "plt.plot(x,m)\n",
        "plt.plot(x,n)\n",
        "plt.title('Improvement of Mean Rewards(M) in increasing Generations(Training)')\n",
        "plt.ylabel('Mean Rewards(M) for Agents : Top 5 in Blue')\n",
        "plt.xlabel('Generations')\n",
        "plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "forming clusers of size =  10\n",
            "created cluster is  [4, 84, 27, 57, 13, 96, 35, 69, 65, 2]\n",
            "created cluster is  [1, 80, 70, 31, 24, 55, 7, 91, 73, 99]\n",
            "created cluster is  [38, 19, 94, 32, 44, 6, 89, 5, 82, 98]\n",
            "created cluster is  [71, 12, 20, 48, 11, 81, 76, 33, 14, 93]\n",
            "created cluster is  [72, 46, 90, 58, 25, 51, 43, 42, 0, 49]\n",
            "created cluster is  [56, 67, 30, 40, 50, 3, 95, 9, 34, 52]\n",
            "created cluster is  [77, 10, 28, 85, 39, 74, 16, 92, 86, 23]\n",
            "created cluster is  [36, 88, 79, 83, 75, 21, 29, 15, 87, 62]\n",
            "created cluster is  [26, 45, 37, 63, 97, 53, 68, 22, 78, 8]\n",
            "created cluster is  [61, 17, 18, 66, 60, 41, 47, 59, 54, 64]\n",
            "\n",
            "\n",
            "Generation  0  | Mean rewards:  188.87268287948584  | Mean of top 5:  603.1632679620367\n",
            "The minimum reward is earned is  31.37335658915823 by the  40 th agent\n",
            "Top  10  scores [88  0 92 79 38  6 13 15 76 74]\n",
            "Rewards for top:  [782.5766726346718, 597.843790187464, 586.2378550800618, 530.0209862435177, 519.1370356644678, 505.83727125768144, 498.0562725742587, 470.7248364495839, 457.43379045473915, 451.1196519837239]\n",
            "Score for elite i  88  is  92.35441223607776\n",
            "Score for elite i  0  is  233.07004234318052\n",
            "Score for elite i  92  is  550.492946677475\n",
            "Score for elite i  79  is  205.3526432338404\n",
            "Score for elite i  38  is  199.90906111377632\n",
            "Score for elite i  6  is  129.25120567626374\n",
            "Score for elite i  13  is  371.90481997045237\n",
            "Score for elite i  15  is  90.739516270343\n",
            "Score for elite i  76  is  134.09256450437437\n",
            "Score for elite i  74  is  147.84027787330646\n",
            "Elite selected with index  92  and score 550.492946677475\n",
            "forming clusers of size =  10\n",
            "created cluster is  [80, 29, 45, 91, 38, 65, 53, 14, 93, 58]\n",
            "created cluster is  [18, 66, 34, 41, 48, 32, 97, 15, 4, 63]\n",
            "created cluster is  [54, 44, 77, 19, 78, 40, 12, 72, 49, 25]\n",
            "created cluster is  [46, 61, 87, 17, 96, 99, 75, 81, 50, 64]\n",
            "created cluster is  [51, 86, 37, 35, 21, 36, 24, 30, 5, 22]\n",
            "created cluster is  [83, 23, 8, 59, 84, 62, 69, 13, 20, 11]\n",
            "created cluster is  [1, 10, 60, 42, 31, 39, 74, 16, 88, 82]\n",
            "created cluster is  [98, 52, 55, 9, 73, 79, 67, 92, 76, 47]\n",
            "created cluster is  [68, 26, 95, 57, 85, 43, 28, 90, 71, 6]\n",
            "created cluster is  [89, 70, 27, 0, 33, 3, 7, 2, 94, 56]\n",
            "\n",
            "\n",
            "Generation  1  | Mean rewards:  193.95240215660095  | Mean of top 5:  745.5582276422052\n",
            "The minimum reward is earned is  34.07440762403123 by the  46 th agent\n",
            "Top  10  scores [88 57 81 82 10 11 76 75 17 59]\n",
            "Rewards for top:  [1030.6326629778605, 756.6349514104844, 688.4493557300231, 633.290181495998, 618.7839865966599, 536.9061250747626, 532.9913312415646, 529.6398601533696, 493.1282392725918, 478.3580982002614]\n",
            "Score for elite i  88  is  143.2222972471721\n",
            "Score for elite i  57  is  397.30978337157654\n",
            "Score for elite i  81  is  303.908644747588\n",
            "Score for elite i  82  is  212.90765617441465\n",
            "Score for elite i  10  is  531.5737336411573\n",
            "Score for elite i  11  is  248.90463064273186\n",
            "Score for elite i  76  is  163.38600300836876\n",
            "Score for elite i  75  is  293.5428286580544\n",
            "Score for elite i  17  is  441.7043389989475\n",
            "Score for elite i  59  is  145.84364298555388\n",
            "Score for elite i  99  is  1029.321205564435\n",
            "Elite selected with index  99  and score 1029.321205564435\n",
            "forming clusers of size =  10\n",
            "created cluster is  [36, 25, 18, 15, 62, 99, 52, 20, 44, 65]\n",
            "created cluster is  [30, 81, 14, 9, 49, 98, 70, 7, 3, 22]\n",
            "created cluster is  [59, 72, 76, 24, 51, 83, 90, 71, 0, 17]\n",
            "created cluster is  [97, 66, 61, 57, 23, 64, 33, 40, 80, 67]\n",
            "created cluster is  [75, 63, 93, 50, 27, 8, 54, 85, 60, 19]\n",
            "created cluster is  [26, 69, 82, 38, 91, 58, 5, 79, 29, 47]\n",
            "created cluster is  [10, 28, 94, 86, 48, 46, 21, 84, 68, 1]\n",
            "created cluster is  [89, 74, 6, 37, 45, 13, 32, 87, 16, 56]\n",
            "created cluster is  [95, 4, 12, 88, 92, 43, 34, 2, 42, 77]\n",
            "created cluster is  [39, 73, 53, 31, 11, 55, 78, 35, 41, 96]\n",
            "\n",
            "\n",
            "Generation  2  | Mean rewards:  215.8333490291457  | Mean of top 5:  958.6576407925608\n",
            "The minimum reward is earned is  31.272690927637015 by the  49 th agent\n",
            "Top  10  scores [ 5 80 32 83 71 53 66 81 90 23]\n",
            "Rewards for top:  [1274.1984421547718, 1041.860961306834, 885.2892348495169, 835.2823982403078, 756.6571674113725, 716.8094893364806, 623.8007738541191, 611.0023880441445, 575.5793575009301, 518.5662470238138]\n",
            "Score for elite i  5  is  325.8563049158564\n",
            "Score for elite i  80  is  180.0333368642493\n",
            "Score for elite i  32  is  243.1238005753368\n",
            "Score for elite i  83  is  198.4406814912863\n",
            "Score for elite i  71  is  75.5877380204053\n",
            "Score for elite i  53  is  204.88165916341524\n",
            "Score for elite i  66  is  150.64624422031648\n",
            "Score for elite i  81  is  217.9672803142377\n",
            "Score for elite i  90  is  158.54850513836897\n",
            "Score for elite i  23  is  231.68556719214743\n",
            "Score for elite i  99  is  228.27578731465005\n",
            "Elite selected with index  5  and score 325.8563049158564\n",
            "forming clusers of size =  10\n",
            "created cluster is  [6, 29, 51, 86, 44, 67, 78, 24, 97, 8]\n",
            "created cluster is  [98, 20, 46, 61, 91, 36, 55, 39, 5, 40]\n",
            "created cluster is  [32, 70, 15, 1, 66, 63, 22, 58, 50, 19]\n",
            "created cluster is  [13, 75, 71, 14, 34, 7, 41, 64, 37, 31]\n",
            "created cluster is  [4, 93, 72, 57, 11, 35, 10, 68, 3, 21]\n",
            "created cluster is  [54, 79, 77, 17, 82, 76, 81, 87, 69, 30]\n",
            "created cluster is  [0, 52, 80, 90, 26, 2, 23, 12, 49, 83]\n",
            "created cluster is  [99, 42, 9, 74, 88, 92, 84, 85, 89, 18]\n",
            "created cluster is  [33, 59, 25, 47, 16, 96, 56, 38, 43, 62]\n",
            "created cluster is  [60, 45, 95, 65, 73, 48, 28, 27, 53, 94]\n",
            "\n",
            "\n",
            "Generation  3  | Mean rewards:  225.65491474773407  | Mean of top 5:  669.7131511161085\n",
            "The minimum reward is earned is  29.569949907379574 by the  8 th agent\n",
            "Top  10  scores [38 96 72  8 31 46 18 91 63 15]\n",
            "Rewards for top:  [747.0054883267891, 683.3574556828576, 658.9016680146078, 645.8983324314127, 613.4028111248756, 597.0195878715346, 580.3215274877941, 541.7994063214612, 533.2902771706318, 506.0650874988929]\n",
            "Score for elite i  38  is  251.1151453556086\n",
            "Score for elite i  96  is  347.34382110441805\n",
            "Score for elite i  72  is  250.59491829098997\n",
            "Score for elite i  8  is  111.56557184979772\n",
            "Score for elite i  31  is  214.8416397355836\n",
            "Score for elite i  46  is  296.64138330062946\n",
            "Score for elite i  18  is  449.41190702762685\n",
            "Score for elite i  91  is  301.2030187144951\n",
            "Score for elite i  63  is  144.32217333953966\n",
            "Score for elite i  15  is  249.08688430645088\n",
            "Score for elite i  99  is  134.43105300477197\n",
            "Elite selected with index  18  and score 449.41190702762685\n",
            "forming clusers of size =  10\n",
            "created cluster is  [53, 32, 12, 0, 52, 81, 34, 56, 16, 28]\n",
            "created cluster is  [6, 22, 88, 96, 20, 2, 10, 70, 15, 14]\n",
            "created cluster is  [79, 42, 82, 86, 68, 19, 4, 21, 7, 99]\n",
            "created cluster is  [77, 78, 89, 84, 18, 46, 58, 69, 57, 85]\n",
            "created cluster is  [65, 80, 48, 54, 3, 8, 62, 17, 55, 27]\n",
            "created cluster is  [49, 83, 72, 73, 40, 64, 76, 98, 25, 43]\n",
            "created cluster is  [13, 36, 33, 26, 71, 39, 23, 9, 95, 61]\n",
            "created cluster is  [94, 74, 66, 30, 93, 1, 29, 59, 97, 44]\n",
            "created cluster is  [41, 38, 47, 35, 87, 63, 45, 24, 90, 37]\n",
            "created cluster is  [92, 50, 11, 75, 31, 91, 5, 60, 67, 51]\n",
            "\n",
            "\n",
            "Generation  4  | Mean rewards:  249.62183210841533  | Mean of top 5:  811.6723036293533\n",
            "The minimum reward is earned is  25.607951042327933 by the  9 th agent\n",
            "Top  10  scores [36 81 37 46 56 98 43 70 38 91]\n",
            "Rewards for top:  [1030.4086686368548, 939.2069910235977, 704.3071296715503, 693.5413550661169, 690.897373748647, 670.6591982906112, 657.7197239416388, 656.6684466554248, 641.3096385571175, 620.2463055716496]\n",
            "Score for elite i  36  is  83.79285198563316\n",
            "Score for elite i  81  is  231.72191048578725\n",
            "Score for elite i  37  is  293.2284790356982\n",
            "Score for elite i  46  is  285.2498450333769\n",
            "Score for elite i  56  is  333.7569982133136\n",
            "Score for elite i  98  is  157.60501918222454\n",
            "Score for elite i  43  is  108.70493366356466\n",
            "Score for elite i  70  is  440.54489035447625\n",
            "Score for elite i  38  is  168.52176164628855\n",
            "Score for elite i  91  is  436.3374556236678\n",
            "Score for elite i  99  is  425.3199275224565\n",
            "Elite selected with index  70  and score 440.54489035447625\n",
            "forming clusers of size =  10\n",
            "created cluster is  [29, 76, 81, 48, 40, 59, 84, 95, 24, 8]\n",
            "created cluster is  [30, 83, 3, 69, 39, 23, 99, 33, 85, 60]\n",
            "created cluster is  [7, 19, 14, 68, 21, 57, 20, 73, 67, 42]\n",
            "created cluster is  [50, 9, 54, 98, 46, 11, 62, 52, 74, 1]\n",
            "created cluster is  [6, 77, 49, 96, 38, 56, 31, 41, 4, 82]\n",
            "created cluster is  [75, 64, 90, 71, 25, 53, 37, 17, 79, 88]\n",
            "created cluster is  [2, 16, 13, 35, 58, 45, 10, 36, 18, 65]\n",
            "created cluster is  [15, 63, 86, 43, 97, 44, 80, 22, 28, 91]\n",
            "created cluster is  [5, 26, 78, 12, 47, 66, 61, 32, 51, 55]\n",
            "created cluster is  [87, 27, 34, 72, 0, 89, 93, 70, 94, 92]\n",
            "\n",
            "\n",
            "Generation  5  | Mean rewards:  213.54073552760246  | Mean of top 5:  649.1838816471043\n",
            "The minimum reward is earned is  41.94842721769688 by the  13 th agent\n",
            "Top  10  scores [41 69  9 46 77 22 14 40  6 51]\n",
            "Rewards for top:  [725.1534913441548, 699.7440895904152, 632.2034899631655, 595.3477142802135, 593.470623057572, 545.4275287179096, 521.1459863900012, 511.87316403550517, 479.91523549156955, 457.55413805164756]\n",
            "Score for elite i  41  is  140.11356628107455\n",
            "Score for elite i  69  is  529.7650248241338\n",
            "Score for elite i  9  is  237.23050486328663\n",
            "Score for elite i  46  is  223.20435622693202\n",
            "Score for elite i  77  is  288.71603615560446\n",
            "Score for elite i  22  is  721.0134429625886\n",
            "Score for elite i  14  is  226.84354988800456\n",
            "Score for elite i  40  is  422.9956927407273\n",
            "Score for elite i  6  is  356.5430191469942\n",
            "Score for elite i  51  is  118.21786930524536\n",
            "Score for elite i  99  is  412.6148205771204\n",
            "Elite selected with index  22  and score 721.0134429625886\n",
            "forming clusers of size =  10\n",
            "created cluster is  [31, 28, 16, 68, 37, 77, 14, 44, 52, 48]\n",
            "created cluster is  [26, 79, 32, 46, 75, 49, 78, 91, 30, 86]\n",
            "created cluster is  [97, 29, 23, 87, 1, 6, 27, 76, 22, 67]\n",
            "created cluster is  [95, 88, 71, 45, 82, 53, 64, 40, 13, 63]\n",
            "created cluster is  [24, 60, 85, 12, 50, 10, 72, 74, 36, 90]\n",
            "created cluster is  [94, 41, 69, 4, 9, 98, 19, 8, 83, 57]\n",
            "created cluster is  [84, 96, 38, 99, 59, 56, 42, 61, 5, 34]\n",
            "created cluster is  [54, 21, 66, 92, 80, 2, 70, 62, 58, 51]\n",
            "created cluster is  [33, 47, 11, 55, 20, 3, 89, 7, 73, 18]\n",
            "created cluster is  [17, 93, 15, 81, 65, 25, 0, 39, 35, 43]\n",
            "\n",
            "\n",
            "Generation  6  | Mean rewards:  235.61381881077853  | Mean of top 5:  645.7574077325651\n",
            "The minimum reward is earned is  24.58318912636633 by the  92 th agent\n",
            "Top  10  scores [75 67 46 33 97 13  9 51 71 82]\n",
            "Rewards for top:  [752.0919304355041, 646.4672574158024, 633.3460579871727, 617.7868021556885, 579.0949906686582, 573.4694599457102, 570.3523706934998, 554.4614178401224, 549.105896542603, 540.2080518676569]\n",
            "Score for elite i  75  is  240.9148807157456\n",
            "Score for elite i  67  is  208.9831869794229\n",
            "Score for elite i  46  is  212.23370615698323\n",
            "Score for elite i  33  is  494.2452938449267\n",
            "Score for elite i  97  is  352.8544083277073\n",
            "Score for elite i  13  is  219.45404534400714\n",
            "Score for elite i  9  is  130.24726496209666\n",
            "Score for elite i  51  is  532.9469656996465\n",
            "Score for elite i  71  is  199.41857561502954\n",
            "Score for elite i  82  is  151.27718239084476\n",
            "Score for elite i  99  is  436.8880002213964\n",
            "Elite selected with index  51  and score 532.9469656996465\n",
            "forming clusers of size =  10\n",
            "created cluster is  [70, 54, 36, 27, 92, 73, 38, 41, 76, 79]\n",
            "created cluster is  [82, 30, 49, 90, 61, 8, 12, 6, 17, 77]\n",
            "created cluster is  [24, 1, 7, 88, 50, 37, 71, 91, 48, 25]\n",
            "created cluster is  [72, 68, 33, 19, 31, 53, 18, 26, 45, 69]\n",
            "created cluster is  [23, 60, 63, 94, 32, 20, 39, 93, 85, 57]\n",
            "created cluster is  [10, 96, 89, 46, 28, 9, 98, 0, 99, 95]\n",
            "created cluster is  [40, 74, 78, 35, 75, 83, 59, 86, 43, 22]\n",
            "created cluster is  [84, 47, 34, 14, 42, 56, 66, 11, 44, 52]\n",
            "created cluster is  [5, 65, 80, 16, 15, 97, 3, 81, 21, 2]\n",
            "created cluster is  [55, 64, 67, 13, 58, 4, 62, 29, 51, 87]\n",
            "\n",
            "\n",
            "Generation  7  | Mean rewards:  207.72004918109167  | Mean of top 5:  738.8482471021805\n",
            "The minimum reward is earned is  32.052233839596305 by the  72 th agent\n",
            "Top  10  scores [ 6 47  0 15 37 14 87 29 22 41]\n",
            "Rewards for top:  [950.543516142953, 818.4257975288928, 775.6586222082802, 579.8224003823075, 569.7908992484696, 542.282234503982, 527.4259008560599, 485.1882607023926, 468.09893141443035, 436.992784757205]\n",
            "Score for elite i  6  is  416.37772943568564\n",
            "Score for elite i  47  is  166.4008450701111\n",
            "Score for elite i  0  is  271.2904287627419\n",
            "Score for elite i  15  is  381.6707711078733\n",
            "Score for elite i  37  is  481.90523653564196\n",
            "Score for elite i  14  is  143.07795568329098\n",
            "Score for elite i  87  is  156.79911940358056\n",
            "Score for elite i  29  is  719.8318846494562\n",
            "Score for elite i  22  is  214.57911530214582\n",
            "Score for elite i  41  is  348.7943127399762\n",
            "Score for elite i  99  is  145.02382715453473\n",
            "Elite selected with index  29  and score 719.8318846494562\n",
            "forming clusers of size =  10\n",
            "created cluster is  [26, 1, 11, 16, 43, 33, 92, 19, 74, 70]\n",
            "created cluster is  [51, 57, 45, 40, 96, 41, 34, 64, 54, 76]\n",
            "created cluster is  [84, 99, 2, 91, 73, 39, 85, 48, 79, 14]\n",
            "created cluster is  [53, 61, 90, 9, 32, 31, 10, 47, 6, 29]\n",
            "created cluster is  [17, 42, 13, 93, 30, 3, 37, 46, 71, 36]\n",
            "created cluster is  [86, 78, 28, 15, 59, 22, 0, 94, 12, 5]\n",
            "created cluster is  [7, 75, 80, 69, 27, 98, 8, 25, 88, 83]\n",
            "created cluster is  [55, 81, 97, 82, 24, 20, 23, 77, 38, 18]\n",
            "created cluster is  [56, 63, 44, 65, 60, 89, 49, 52, 21, 4]\n",
            "created cluster is  [62, 58, 35, 87, 68, 67, 72, 66, 95, 50]\n",
            "\n",
            "\n",
            "Generation  8  | Mean rewards:  218.43330683435698  | Mean of top 5:  725.1177489238153\n",
            "The minimum reward is earned is  29.49428299767202 by the  34 th agent\n",
            "Top  10  scores [70 57 77 22  3 79 94 31 89 27]\n",
            "Rewards for top:  [896.602608078916, 804.8386246042687, 656.2697911006233, 639.1372446690001, 628.7404761662685, 597.7777922348977, 592.8228854598415, 572.5161404073156, 516.5902493068894, 484.99933146747776]\n",
            "Score for elite i  70  is  705.382629743446\n",
            "Score for elite i  57  is  948.6575765129561\n",
            "Score for elite i  77  is  384.5227037522253\n",
            "Score for elite i  22  is  550.9049517633392\n",
            "Score for elite i  3  is  191.078500983576\n",
            "Score for elite i  79  is  347.00186059891064\n",
            "Score for elite i  94  is  192.76494630584654\n",
            "Score for elite i  31  is  237.4354520194607\n",
            "Score for elite i  89  is  174.04118986613722\n",
            "Score for elite i  27  is  192.50132285959845\n",
            "Score for elite i  99  is  282.1583514494837\n",
            "Elite selected with index  57  and score 948.6575765129561\n",
            "forming clusers of size =  10\n",
            "created cluster is  [42, 90, 26, 15, 8, 85, 99, 86, 76, 19]\n",
            "created cluster is  [44, 37, 25, 93, 29, 88, 69, 35, 24, 21]\n",
            "created cluster is  [0, 61, 30, 34, 87, 75, 17, 91, 70, 57]\n",
            "created cluster is  [51, 71, 94, 84, 2, 89, 60, 48, 27, 38]\n",
            "created cluster is  [6, 58, 62, 1, 33, 23, 63, 98, 56, 82]\n",
            "created cluster is  [95, 12, 31, 52, 67, 7, 32, 68, 49, 40]\n",
            "created cluster is  [55, 74, 18, 73, 47, 4, 45, 10, 80, 46]\n",
            "created cluster is  [50, 9, 13, 53, 77, 36, 5, 20, 39, 72]\n",
            "created cluster is  [14, 59, 28, 22, 97, 66, 65, 96, 43, 81]\n",
            "created cluster is  [3, 16, 92, 64, 41, 79, 54, 83, 78, 11]\n",
            "\n",
            "\n",
            "Generation  9  | Mean rewards:  245.21098664416823  | Mean of top 5:  847.6405171660642\n",
            "The minimum reward is earned is  44.406430773768044 by the  68 th agent\n",
            "Top  10  scores [32 23 62 70 48 24  7 81 82 11]\n",
            "Rewards for top:  [931.8422837594047, 904.3287335522998, 879.5404298043568, 779.4191146544072, 743.072024059853, 706.5021651941231, 675.6111005865276, 638.312701925921, 618.2331049812794, 589.8754435258052]\n",
            "Score for elite i  32  is  91.31709481029489\n",
            "Score for elite i  23  is  117.11735604781252\n",
            "Score for elite i  62  is  288.7281652104319\n",
            "Score for elite i  70  is  360.5873056888112\n",
            "Score for elite i  48  is  84.67572695232495\n",
            "Score for elite i  24  is  331.00396737970425\n",
            "Score for elite i  7  is  195.03452779536124\n",
            "Score for elite i  81  is  94.98295358903303\n",
            "Score for elite i  82  is  127.41177396039822\n",
            "Score for elite i  11  is  304.6027804306385\n",
            "Score for elite i  99  is  787.8077633511108\n",
            "Elite selected with index  99  and score 787.8077633511108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slkXfEV71A7U"
      },
      "source": [
        "\n",
        "def play_agent(agent):\n",
        "        env = gym.make(\"CartPole-v0\")\n",
        "        \n",
        "        env_record = Monitor(env, './video', force=True)\n",
        "        observation = env_record.reset()\n",
        "        last_observation = observation\n",
        "        r=0\n",
        "        j=[]\n",
        "        episode_durations=[]\n",
        "        timestep=0\n",
        "        for timestep in range(1000):\n",
        "            env_record.render()\n",
        "            inp = torch.tensor(observation).type('torch.FloatTensor').view(1,-1)\n",
        "            output_probabilities = agent(inp).detach().numpy()[0]\n",
        "            action = np.random.choice(range(game_actions), 1, p=output_probabilities).item()\n",
        "            new_observation, reward, done, info = env_record.step(action)\n",
        "            r=r+reward\n",
        "            j.append(r)\n",
        "            observation = new_observation\n",
        "\n",
        "            if(done):\n",
        "                break\n",
        "\n",
        "        env_record.close()\n",
        "\n",
        "        print(\"Total Collected Rewards: \",r)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq7kESgH1A7U",
        "outputId": "ad94d4b1-0124-466c-93a2-7de49d98d7a0"
      },
      "source": [
        "play_agent(agents[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Collected Rewards:  62.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}